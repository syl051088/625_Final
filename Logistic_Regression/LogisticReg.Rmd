---
title: "Logistic Regression"
author: "Yulin Shao"
date: "2024-10-30"
output: pdf_document
---

```{r setup, include=FALSE}
# Load necessary libraries
library(dplyr)
library(mice)
library(tidyverse)
library(pROC)
library(caret)
```

```{r data processing}
# Load the dataset
heart_data = read.csv("~/Desktop/UMICH/FALL 2024/BIostat 625/625_Final/dataset_cleaned/heart_disease_dataset.csv")

# Inspect the first few rows of the dataset
head(heart_data)

# Convert relevant columns to factors
heart_data = heart_data %>%
  mutate(
    chol = if_else(chol == 0, NA_real_, chol),
    num = as.factor(ifelse(num > 0, 1, 0))  # 1 for disease, 0 for no disease
  )

# Calculate proportion of NAs for each column
na_proportions = heart_data %>%
  summarise(across(everything(),
                  ~round(mean(is.na(.)) * 100, 2),
                  .names = "{.col}_NA_percent")) %>%
  pivot_longer(everything(),
               names_to = "variable",
               values_to = "na_percent") %>%
  arrange(desc(na_percent))

# Print results
print(na_proportions, n = nrow(na_proportions))

# Clean the dataset
heart_data = heart_data %>%
  # Remove specified columns
  select(-slope, -ca, -thal)

# Check missing data pattern
md.pattern(heart_data)
```

```{r imputation and model training}
# Set seed for reproducibility
set.seed(123)

# Perform multiple imputation
imputed_data = mice(heart_data, m = 5, method = 'pmm')
summary(imputed_data)

sample_index = sample(seq_len(nrow(completed_data)), size = 0.8 * nrow(completed_data))
predicted_probs = matrix(NA, nrow = 5, ncol=nrow(heart_data)-length(sample_index))
# # Loop over all imputed datasets
for (i in 1:5) {
  completed_data = complete(imputed_data, action = i)
  train_data = completed_data[sample_index, ]
  test_data = completed_data[-sample_index, ]

  # Fit and evaluate models here for each imputed dataset
  model = with(train_data, glm(num ~ age + sex + cp + trestbps + chol + fbs +
             restecg + thalach + exang + oldpeak,
             family = binomial))
  
  # Predict probabilities on the test set
  predicted_probs[i,] = predict(model, newdata = test_data, type = "response")
}
```

```{r results}
predicted = colMeans(predicted_probs)
# Convert probabilities to binary predictions with a threshold of 0.5
predictions = ifelse(predicted > 0.5, 1, 0)
true_lable = factor(test_data$num)
# Create confusion matrix and derive metrics
conf_matrix = confusionMatrix(factor(predictions), true_lable, positive="1")

# Print key metrics
# Extract metrics
accuracy = conf_matrix$overall["Accuracy"]
sensitivity = conf_matrix$byClass["Sensitivity"]
specificity = conf_matrix$byClass["Specificity"]
precision = conf_matrix$byClass["Pos Pred Value"]
f1_score = 2 * (precision * sensitivity) / (precision + sensitivity)

cat("Accuracy:", accuracy, "\n")
cat("Sensitivity (Recall):", sensitivity, "\n")
cat("Specificity:", specificity, "\n")
cat("Precision:", precision, "\n")
cat("F1 Score:", f1_score, "\n")

# Compute ROC and AUC
roc_curve = roc(true_lable, predicted)
auc_value = auc(roc_curve)

cat("AUC:", auc_value, "\n")

# Plot ROC Curve
plot(roc_curve, main = "ROC Curve", col = "blue")
png("ROC_Curve_Logistic_Regression_Model.png")
dev.off()
```