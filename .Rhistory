# Load necessary libraries
library(dplyr)        # Data manipulation
library(caret)        # For model training and evaluation
library(rpart)        # For decision trees
library(rpart.plot)   # For plotting decision trees
library(pROC)         # For ROC/AUC
library(doParallel)   # For parallel computing
install.packages(doParallel)
install.packages("doParallel")
# Load necessary libraries
library(dplyr)        # Data manipulation
library(caret)        # For model training and evaluation
library(rpart)        # For decision trees
library(rpart.plot)   # For plotting decision trees
library(pROC)         # For ROC/AUC
library(doParallel)   # For parallel computing
library(ggplot2)      # For optional plotting
# Ensure reproducible results
set.seed(123)
# NOTE: Adjust file paths to your local environment
train_data <- read.csv("~/Desktop/625_Final/data/train_data.csv")
test_data <- read.csv("~/Desktop/625_Final/test_data.csv")
# NOTE: Adjust file paths to your local environment
train_data <- read.csv("~/Desktop/625_Final/data/train_data.csv")
test_data <- read.csv("~/Desktop/625_Final/data/test_data.csv")
# Quick structure check
str(train_data)
str(test_data)
# If 'Diabetes_binary' is numeric or character, convert it to factor
# Levels assumed: "0" = No, "1" = Yes (Pre/Diabetic)
train_data$Diabetes_binary <- factor(train_data$Diabetes_binary,
levels = c("0", "1"),
labels = c("No", "Yes"))
test_data$Diabetes_binary <- factor(test_data$Diabetes_binary,
levels = c("0", "1"),
labels = c("No", "Yes"))
# Double-check class distribution
table(train_data$Diabetes_binary)
table(test_data$Diabetes_binary)
# Because the dataset is quite large, let's do minimal EDA to avoid heavy memory usage.
# Basic summary stats
summary(train_data)
# Distribution of target in training data
ggplot(train_data, aes(x = Diabetes_binary)) +
geom_bar(fill = "blue") +
theme_minimal() +
labs(title = "Distribution of Diabetes_binary in Training Set",
x = "Diabetes Status",
y = "Count")
# Detect cores and create cluster
num_cores <- parallel::detectCores() - 1  # Reserve 1 core for OS overhead
cl <- makeCluster(num_cores)
registerDoParallel(cl)
cat("Parallel backend registered with", num_cores, "cores.\n")
# 5- or 10-fold CV is typical for large datasets.
# More folds = potentially better estimates but slower training.
# We'll choose 5-fold to reduce training time.
train_control <- trainControl(
method = "cv",
number = 5,
verboseIter = FALSE,
classProbs = TRUE,   # needed for ROC in caret
summaryFunction = twoClassSummary,  # Use AUC, Sensitivity, Specificity
allowParallel = TRUE  # KEY: enable parallel
)
# Define a grid of complexity parameters.
# If you want a faster run, reduce the size of this grid.
cp_grid <- expand.grid(cp = seq(0.0005, 0.02, by = 0.0005))
# We'll measure performance by "ROC" to get the best sensitivity/specificity tradeoff.
# You could also use "Accuracy". For classification, either approach is valid.
set.seed(123)
system.time({
dt_model <- train(
Diabetes_binary ~ .,               # All features except the target
data = train_data,
method = "rpart",
metric = "ROC",                    # Or "Accuracy" if desired
trControl = train_control,
tuneGrid = cp_grid
)
})
# Best complexity parameter
cat("Best CP found:", dt_model$bestTune$cp, "\n")
# Predictions
dt_preds <- predict(dt_model, newdata = test_data)
dt_probs <- predict(dt_model, newdata = test_data, type = "prob")[, "Yes"]  # Probability of "Yes"
# Confusion Matrix
dt_conf_mat <- confusionMatrix(dt_preds, test_data$Diabetes_binary, positive = "Yes")
print(dt_conf_mat)
# Extract key metrics
accuracy_dt  <- dt_conf_mat$overall["Accuracy"]
sensitivity_dt <- dt_conf_mat$byClass["Sensitivity"]
specificity_dt <- dt_conf_mat$byClass["Specificity"]
precision_dt   <- dt_conf_mat$byClass["Pos Pred Value"]
f1_dt <- 2 * (precision_dt * sensitivity_dt) / (precision_dt + sensitivity_dt)
cat("Accuracy:", round(accuracy_dt, 4), "\n")
cat("Sensitivity:", round(sensitivity_dt, 4), "\n")
cat("Specificity:", round(specificity_dt, 4), "\n")
cat("Precision:", round(precision_dt, 4), "\n")
cat("F1 Score:", round(f1_dt, 4), "\n")
# ROC and AUC
dt_roc <- roc(test_data$Diabetes_binary, dt_probs)
dt_auc <- auc(dt_roc)
cat("AUC:", round(dt_auc, 4), "\n")
# Plotting a large tree can be memory-intensive for huge datasets,
# but here is how you’d do it:
rpart.plot(
dt_model$finalModel,
type = 2,
extra = 104,
fallen.leaves = TRUE,
main = "Decision Tree for Diabetes Prediction"
)
dt_var_imp <- varImp(dt_model, scale = FALSE)
print(dt_var_imp)
stopCluster(cl)
registerDoSEQ()  # revert to sequential
cat("Parallel backend stopped.\n")
# Load necessary libraries
library(dplyr)
library(caret)
library(rpart)
library(rpart.plot)
library(pROC)
library(doParallel)
# For reproducible results
set.seed(123)
# Adjust file paths as needed
train_data <- read.csv("~/Desktop/625_Final/data/train_data.csv")
test_data  <- read.csv("~/Desktop/625_Final/data/test_data.csv")
# Convert numeric Diabetes_binary to factor: 0 = No, 1 = Yes
train_data$Diabetes_binary <- factor(train_data$Diabetes_binary, levels = c("0", "1"), labels = c("No", "Yes"))
test_data$Diabetes_binary  <- factor(test_data$Diabetes_binary,  levels = c("0", "1"), labels = c("No", "Yes"))
# Check class distribution
table(train_data$Diabetes_binary)
table(test_data$Diabetes_binary)
# Detect cores and create cluster
num_cores <- parallel::detectCores() - 1
cl <- makeCluster(num_cores)
registerDoParallel(cl)
cat("Parallel backend registered with", num_cores, "cores.\n")
train_control <- trainControl(
method = "cv",
number = 5,              # Fewer folds = faster training (typical: 5 or 10)
classProbs = TRUE,       # Needed for ROC
summaryFunction = twoClassSummary,
allowParallel = TRUE
)
# If you want faster runs, reduce the range/step of cp
cp_grid <- expand.grid(cp = seq(0.0005, 0.02, by = 0.0005))
system.time({
dt_model <- train(
Diabetes_binary ~ .,
data      = train_data,
method    = "rpart",
metric    = "ROC",        # or "Accuracy"
trControl = train_control,
tuneGrid  = cp_grid
)
})
cat("Best CP found:", dt_model$bestTune$cp, "\n")
# Predictions and probabilities
dt_preds <- predict(dt_model, newdata = test_data)
dt_probs <- predict(dt_model, newdata = test_data, type = "prob")[, "Yes"]
# Confusion Matrix
dt_conf_mat <- confusionMatrix(dt_preds, test_data$Diabetes_binary, positive = "Yes")
print(dt_conf_mat)
# Metrics
accuracy    <- dt_conf_mat$overall["Accuracy"]
sensitivity <- dt_conf_mat$byClass["Sensitivity"]
specificity <- dt_conf_mat$byClass["Specificity"]
precision   <- dt_conf_mat$byClass["Pos Pred Value"]
f1_score    <- 2 * (precision * sensitivity) / (precision + sensitivity)
cat("Accuracy:",    round(accuracy, 4),    "\n")
cat("Sensitivity:", round(sensitivity, 4), "\n")
cat("Specificity:", round(specificity, 4), "\n")
cat("Precision:",   round(precision, 4),   "\n")
cat("F1 Score:",    round(f1_score, 4),    "\n")
# AUC
roc_obj <- roc(test_data$Diabetes_binary, dt_probs)
cat("AUC:", round(auc(roc_obj), 4), "\n")
# Plotting a large tree can be memory-intensive for big datasets.
rpart.plot(
dt_model$finalModel,
type = 2,
extra = 104,
fallen.leaves = TRUE,
main = "Decision Tree for Diabetes Prediction"
)
var_imp <- varImp(dt_model, scale = FALSE)
print(var_imp)
stopCluster(cl)
registerDoSEQ()
cat("Parallel backend stopped.\n")
# Load necessary libraries
library(dplyr)
library(caret)
library(rpart)
library(rpart.plot)
library(pROC)
library(doParallel)
# For reproducible results
set.seed(123)
# Adjust file paths as needed
train_data <- read.csv("~/Desktop/625_Final/data/train_data.csv")
test_data  <- read.csv("~/Desktop/625_Final/data/test_data.csv")
# Convert numeric Diabetes_binary to factor: 0 = No, 1 = Yes
train_data$Diabetes_binary <- factor(train_data$Diabetes_binary, levels = c("0", "1"), labels = c("No", "Yes"))
test_data$Diabetes_binary  <- factor(test_data$Diabetes_binary,  levels = c("0", "1"), labels = c("No", "Yes"))
# Check class distribution
table(train_data$Diabetes_binary)
table(test_data$Diabetes_binary)
# Detect cores and create cluster
num_cores <- parallel::detectCores() - 1
cl <- makeCluster(num_cores)
registerDoParallel(cl)
cat("Parallel backend registered with", num_cores, "cores.\n")
train_control <- trainControl(
method = "cv",
number = 5,              # Fewer folds = faster training (typical: 5 or 10)
classProbs = TRUE,       # Needed for ROC
summaryFunction = twoClassSummary,
allowParallel = TRUE
)
# If you want faster runs, reduce the range/step of cp
cp_grid <- expand.grid(cp = seq(0.0005, 0.02, by = 0.0005))
system.time({
dt_model <- train(
Diabetes_binary ~ .,
data      = train_data,
method    = "rpart",
metric    = "ROC",        # or "Accuracy"
trControl = train_control,
tuneGrid  = cp_grid
)
})
cat("Best CP found:", dt_model$bestTune$cp, "\n")
# Predictions and probabilities
dt_preds <- predict(dt_model, newdata = test_data)
dt_probs <- predict(dt_model, newdata = test_data, type = "prob")[, "Yes"]
# Confusion Matrix
dt_conf_mat <- confusionMatrix(dt_preds, test_data$Diabetes_binary, positive = "Yes")
print(dt_conf_mat)
# Metrics
accuracy    <- dt_conf_mat$overall["Accuracy"]
sensitivity <- dt_conf_mat$byClass["Sensitivity"]
specificity <- dt_conf_mat$byClass["Specificity"]
precision   <- dt_conf_mat$byClass["Pos Pred Value"]
f1_score    <- 2 * (precision * sensitivity) / (precision + sensitivity)
cat("Accuracy:",    round(accuracy, 4),    "\n")
cat("Sensitivity:", round(sensitivity, 4), "\n")
cat("Specificity:", round(specificity, 4), "\n")
cat("Precision:",   round(precision, 4),   "\n")
cat("F1 Score:",    round(f1_score, 4),    "\n")
# AUC
roc_obj <- roc(test_data$Diabetes_binary, dt_probs)
cat("AUC:", round(auc(roc_obj), 4), "\n")
# Plotting a large tree can be memory-intensive for big datasets.
rpart.plot(
dt_model$finalModel,
type = 2,
extra = 104,
fallen.leaves = TRUE,
main = "Decision Tree for Diabetes Prediction"
)
stopCluster(cl)
registerDoSEQ()
cat("Parallel backend stopped.\n")
# Load necessary libraries
library(dplyr)
library(caret)
library(rpart)
library(rpart.plot)
library(pROC)
library(doParallel)
# Reproducibility
set.seed(123)
# Load data (adjust paths as needed)
train_data <- read.csv("~/Desktop/625_Final/data/train_data.csv")
test_data  <- read.csv("~/Desktop/625_Final/data/test_data.csv")
# Convert numeric target to factor: 0 = No, 1 = Yes
train_data$Diabetes_binary <- factor(train_data$Diabetes_binary, levels = c("0", "1"), labels = c("No", "Yes"))
test_data$Diabetes_binary  <- factor(test_data$Diabetes_binary, levels = c("0", "1"), labels = c("No", "Yes"))
# Parallel setup
num_cores <- parallel::detectCores() - 1
cl <- makeCluster(num_cores)
registerDoParallel(cl)
# Define cross-validation and grid
train_control <- trainControl(
method = "cv",
number = 5,               # 5-fold CV for speed & reliability
classProbs = TRUE,
summaryFunction = twoClassSummary,
allowParallel = TRUE
)
# Tuning grid for complexity parameter
cp_grid <- expand.grid(cp = seq(0.0005, 0.02, by = 0.0005))
# Train Decision Tree with parallel CV
dt_model <- train(
Diabetes_binary ~ .,
data      = train_data,
method    = "rpart",
metric    = "ROC",       # or "Accuracy"
trControl = train_control,
tuneGrid  = cp_grid
)
# Predictions
dt_preds <- predict(dt_model, newdata = test_data)
dt_probs <- predict(dt_model, newdata = test_data, type = "prob")[, "Yes"]
# Confusion Matrix & Metrics
dt_conf_mat <- confusionMatrix(dt_preds, test_data$Diabetes_binary, positive = "Yes")
accuracy    <- dt_conf_mat$overall["Accuracy"]
sensitivity <- dt_conf_mat$byClass["Sensitivity"]
specificity <- dt_conf_mat$byClass["Specificity"]
precision   <- dt_conf_mat$byClass["Pos Pred Value"]
f1_score    <- 2 * (precision * sensitivity) / (precision + sensitivity)
cat("Best CP:", dt_model$bestTune$cp, "\n")
cat("Accuracy:", round(accuracy, 4), "\n")
cat("Sensitivity:", round(sensitivity, 4), "\n")
cat("Specificity:", round(specificity, 4), "\n")
cat("Precision:", round(precision, 4), "\n")
cat("F1 Score:", round(f1_score, 4), "\n")
# AUC
roc_obj <- roc(test_data$Diabetes_binary, dt_probs)
cat("AUC:", round(auc(roc_obj), 4), "\n")
# Optional: Tree Plot (can be memory-intensive)
# rpart.plot(dt_model$finalModel, type = 2, extra = 104, fallen.leaves = TRUE)
# Stop parallel cluster
stopCluster(cl)
registerDoSEQ()
# Load necessary libraries
library(dplyr)
library(caret)
library(rpart)
library(rpart.plot)
library(pROC)
library(doParallel)
# For reproducible results
set.seed(123)
# Adjust file paths as needed
train_data <- read.csv("~/Desktop/625_Final/data/train_data.csv")
test_data  <- read.csv("~/Desktop/625_Final/data/test_data.csv")
# Convert numeric Diabetes_binary to factor: 0 = No, 1 = Yes
train_data$Diabetes_binary <- factor(train_data$Diabetes_binary, levels = c("0", "1"), labels = c("No", "Yes"))
test_data$Diabetes_binary  <- factor(test_data$Diabetes_binary,  levels = c("0", "1"), labels = c("No", "Yes"))
# Check class distribution
table(train_data$Diabetes_binary)
table(test_data$Diabetes_binary)
num_cores <- parallel::detectCores() - 1
cl <- makeCluster(num_cores)
registerDoParallel(cl)
cat("Parallel backend registered with", num_cores, "cores.\n")
train_control <- trainControl(
method = "cv",
number = 5,
classProbs = TRUE,
summaryFunction = twoClassSummary,
allowParallel = TRUE
)
# Grid for complexity parameter tuning
cp_grid <- expand.grid(cp = seq(0.0005, 0.02, by = 0.0005))
dt_model <- train(
Diabetes_binary ~ .,
data      = train_data,
method    = "rpart",
metric    = "ROC",
trControl = train_control,
tuneGrid  = cp_grid
)
cat("Best CP found:", dt_model$bestTune$cp, "\n")
dt_preds <- predict(dt_model, newdata = test_data)
dt_probs <- predict(dt_model, newdata = test_data, type = "prob")[, "Yes"]
dt_conf_mat <- confusionMatrix(dt_preds, test_data$Diabetes_binary, positive = "Yes")
print(dt_conf_mat)
accuracy    <- dt_conf_mat$overall["Accuracy"]
sensitivity <- dt_conf_mat$byClass["Sensitivity"]
specificity <- dt_conf_mat$byClass["Specificity"]
precision   <- dt_conf_mat$byClass["Pos Pred Value"]
f1_score    <- 2 * (precision * sensitivity) / (precision + sensitivity)
cat("Accuracy:",    round(accuracy, 4), "\n")
cat("Sensitivity:", round(sensitivity, 4), "\n")
cat("Specificity:", round(specificity, 4), "\n")
cat("Precision:",   round(precision, 4), "\n")
cat("F1 Score:",    round(f1_score, 4), "\n")
# ROC and AUC
roc_obj <- roc(test_data$Diabetes_binary, dt_probs)
cat("AUC:", round(auc(roc_obj), 4), "\n")
rpart.plot(
dt_model$finalModel,
type = 2,
extra = 104,
fallen.leaves = TRUE,
main = "Decision Tree for Diabetes Prediction"
)
stopCluster(cl)
registerDoSEQ()
library(ggplot2)
model_accuracy <- data.frame(
Model    = c("Logistic Regression", "KNN", "Decision Tree", "Random Forest", "XGBoost"),
Accuracy = c(0.70, 0.72, 0.7376, 0.7481, 0.75),
Speedup  = c("3x Faster", "62% Faster", "Parallelized CV", "362s → 3.42s", "Optimized Parallel Trees")
)
model_accuracy$Model <- factor(
model_accuracy$Model,
levels = model_accuracy$Model[order(model_accuracy$Accuracy, decreasing = TRUE)]
)
ggplot(model_accuracy, aes(x = Model, y = Accuracy, fill = Model)) +
geom_col(width = 0.6) +
geom_text(aes(label = paste(Accuracy, "\n", Speedup), y = Accuracy + 0.015), size = 3.5) +
labs(
title = "Accuracy and Speed Improvements Across Models (CDC Diabetes)",
x = NULL,
y = "Accuracy"
) +
theme_minimal(base_size = 12) +
theme(
axis.text.x = element_text(angle = 45, hjust = 1),
legend.position = "none",
plot.title = element_text(hjust = 0.5)
)
library(ggplot2)
model_accuracy <- data.frame(
Model    = c("Logistic Regression", "KNN", "Decision Tree", "Random Forest", "XGBoost"),
Accuracy = c(0.70, 0.72, 0.7376, 0.7481, 0.75)
)
model_accuracy$Model <- factor(
model_accuracy$Model,
levels = model_accuracy$Model[order(model_accuracy$Accuracy, decreasing = TRUE)]
)
ggplot(model_accuracy, aes(x = Model, y = Accuracy, fill = Model)) +
geom_col(width = 0.6) +
geom_text(aes(label = Accuracy, y = Accuracy + 0.015), size = 3.5) +
labs(
title = "Accuracy Comparison Across Models (CDC Diabetes)",
x = NULL,
y = "Accuracy"
) +
theme_minimal(base_size = 12) +
theme(
axis.text.x = element_text(angle = 45, hjust = 1),
legend.position = "none",
plot.title = element_text(hjust = 0.5)
) +
geom_label(
data = subset(model_accuracy, Accuracy == max(model_accuracy$Accuracy)),
aes(label = "Best Model", y = Accuracy + 0.05),
color = "white",
fill = "red",
fontface = "bold",
label.padding = unit(0.25, "lines"),
show.legend = FALSE
)
library(ggplot2)
model_accuracy <- data.frame(
Model    = c("Logistic Regression", "KNN", "Decision Tree", "Random Forest", "XGBoost"),
Accuracy = c(0.744, 0.72, 0.738, 0.748, 0.75)
)
model_accuracy$Model <- factor(
model_accuracy$Model,
levels = model_accuracy$Model[order(model_accuracy$Accuracy, decreasing = TRUE)]
)
ggplot(model_accuracy, aes(x = Model, y = Accuracy, fill = Model)) +
geom_col(width = 0.6) +
geom_text(aes(label = Accuracy, y = Accuracy + 0.015), size = 3.5) +
labs(
title = "Accuracy Comparison Across Models (CDC Diabetes)",
x = NULL,
y = "Accuracy"
) +
theme_minimal(base_size = 12) +
theme(
axis.text.x = element_text(angle = 45, hjust = 1),
legend.position = "none",
plot.title = element_text(hjust = 0.5)
) +
geom_label(
data = subset(model_accuracy, Accuracy == max(model_accuracy$Accuracy)),
aes(label = "Best Model", y = Accuracy + 0.05),
color = "white",
fill = "red",
fontface = "bold",
label.padding = unit(0.25, "lines"),
show.legend = FALSE
)
